# Inventory for an 8-node cluster, to be used for ex with config "cluster_3M2E3W"

# IDEA: Adding localhost to the inventory, so that it is part of "groups.all" (and it also gets important "set_fact"  )
# but only works when avoiding ssh, via ansible_connection=local
[local]
localhost  ansible_connection=local


[edge1]
eval-cdp-public0.internal.cloudapp.net host_template=Edge1 ansible_host=52.170.192.213

[edge2]
eval-cdp-public1.internal.cloudapp.net host_template=Edge2 ansible_host=52.170.193.21

[cloudera_manager:children]
edge1

[edge:children]
edge1
edge2

[cluster_edge_nodes:children]
edge

[cluster_master_nodes]
eval-cdp-public2.internal.cloudapp.net host_template=Master1 ansible_host=52.170.192.205
eval-cdp-public3.internal.cloudapp.net host_template=Master2 ansible_host=52.170.192.236
eval-cdp-public4.internal.cloudapp.net host_template=Master3 ansible_host=52.170.192.172

[cluster_worker_nodes]
eval-cdp-public5.internal.cloudapp.net host_template=Workers ansible_host=52.170.197.255
eval-cdp-public6.internal.cloudapp.net host_template=Workers ansible_host=52.170.198.178
eval-cdp-public7.internal.cloudapp.net host_template=Workers ansible_host=52.170.86.155

[cluster_worker_nodes:vars]
host_template=Workers

[cluster:children]
cluster_edge_nodes
cluster_master_nodes
cluster_worker_nodes


[db_server:children]
cloudera_manager

[deployment:children]
cluster
db_server

# Note: TF deploys our OS users incl. ssh-pub key, so no more need to set the "ansible_user"..
#[deployment:vars]
# Ansible will defer to the running SSH Agent for relevant keys
# Set the following to hardcode the SSH private key for the instances
# ansible_ssh_private_key_file=~/.ssh/mykey.pem  
#ansible_user=centos
#ansible_user=adminuser
